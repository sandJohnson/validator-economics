---
title: "Validator Economics: Sync committee selection"
author:
- name: Sandra Johnson
  url: https://twitter.com/sandJohnson
  affiliation: Consensys Software Inc (Research Group)
date: "`r Sys.Date()`"
description: 
  Calculation and visualisation of sync committee selection probabilities for increased maximum effective balance.
editor_options: 
  markdown: 
    wrap: 72
---

This R script is in GitHub \~/rig-sandbox/R scripts The output is
included in the document "Validator Economics: Variable min validator
deposit size, EF Academic Grant ID: FY23-1030, DRAFT MODEL, CHALLENGES &
POTENTIAL MITIGATIONS (MAXEB - EIP-7521)" The source LaTeX files are in
GitHub \~/validator-economics/documents

```{r message=FALSE}
library(data.table)
library(ggplot2)
#library(glue)          # Not really using glue in this Notebook, but it is useful!
#library(jsonlite)
library(knitr)
library(lubridate)
library(rmarkdown)
library(skimr)
library(tibble)
library(tidyverse)

options(digits=10)
options(scipen = 999) 

# See knit options in https://www.r-bloggers.com/2021/03/default-knitr-options-and-hooks/ 
knitr::opts_chunk$set(dpi = if (knitr::is_latex_output()) 72 else 300,
                      echo=FALSE)
```
## Fetch R functions to use
```{r}
source("sync_functions.R")
```


## Sync committee selection

The probability of a validator being selected to participate in the sync committee
adheres to the following process: 
1) The validator indices are shuffled 
2) One candidate validator results from the shuffled index
3) A random byte is generated for this candidate (note this candidate may have been chosen before & more than likely with a different generated random byte)
4) A comparison is made between the candidate validator's effective balance * maximum bytes value (255) and MaxEB * random byte generated. If the first term is bigger than the second, then the validator is added to the sync committee.
5) Another iteration of the loop is executed until we have chosen enough validators (each member of the committee is present >= 1) to make up the sync committee

This appears to be very similar at first glance to proposer selection, but the difference here is that 
we are sampling WITH REPLACEMENT. Therefore each validator could be chosen more than once and the probabilities of being chosen do not change with each draw.

(NB: CHECK THAT PROPOSER SELECTION DOES IN FACT SAMPLE W/O REPLACEMENT, BECAUSE LOOKING AT THE CODE IT DOES NOT APPEAR TO ME TO BE THE CASE!!)

###  Generate 255 random bytes that we will use to combine with validators selected from the active validator set

```{r cache=TRUE}
# Generate 255 random bytes that we will use to combine with validators selected from the active validator set
# ------------------------------------------------------------------------------------------------------------
set.seed(1)

random_byte_values_sync <- runif(7680,0,255)
## ----------------------------------------------
r_int_sync <- floor(random_byte_values_sync)
r_sync <- tibble(r_int_sync)

df_sync_random <- r_sync %>%
  group_by(r_int_sync) %>%
  summarise(y = n()) %>%
  arrange(r_int_sync)

# Check proportions of random values generated
df_sync_random_sync  <- df_sync_random  %>%
  mutate(prob = y/sum(y)) 



```



```{r}
# ---------------------------------------------------------------------------------------
#' Example Scenario: prior to EIP-7521
#' -----------------------------------
#' - Three staker groups: A, B, C
#' - All validators owned by the three staker groups are solo stakers
#' - A, B, and C have all staked the same amount, i.e. run the same number of validators
# ---------------------------------------------------------------------------------------
```
# Example Scenario: prior to EIP-7521

- The total number of validators (n) in the active validator set is more than 255 (2560*3=7680) 
- Three staker groups: A, B, C
- All validators owned by the three staker groups are solo stakers
- A, B, and C have all staked the same amount, i.e. run the same number of validators = 2560

```{r}

```
## Example Scenario: post EIP-7521

 - The total number of validators (n) in the active validator set is more than 255 (128*3=384) 
 - Three staker groups: A, B, C
 - The validators owned by the three staker groups have been consolidated in different ways
 - A, B, and C have all staked the same amount, so even though the number of validators owned by each group may differ, they all have the same number of virtual validators.

### NOTE: The concept of a virtual validator needs to work with validators that are not  multiples of 32 ETH.
Reason being once we are compounding to various validators we will have validators that have fractions of 32 ETH added to them over time.

- What we want to visualise is the probability distribution for membership of the sync committee for each of the staker groups:
 1. As is currently the case
 2. After EIP-7521 has been implemented
```{r}
# Binomial distribution for sync committee selection
# ---------------------------------------------------
# Pre-EIP-7521, the probability of one of the validators of each of the stakers being in the
# sync committee is given by:
scenario_pre_EIP7521_prob <- 1/3          # 2560/7680 

# For each of the groups, we want to visualise the probability that one of their validators is chosen to be included in the sync committee
# P(X >= 1) = 1 - P(X=0), i.e. it is 1 - probability that none of the validators in that staker group is in the sync committee

# This is the density of the probability of the number of validators selected for the sync committee test
n_sync <- 255       # sync committee size 
x <- seq(0,255,1)
p_bin <- scenario_pre_EIP7521_prob
pre_eip_dbin <- dbinom(x,n_sync, p_bin)

plot(x,dbinom(x,n_sync, p_bin),
     type='h',
     ylab ='Probability',
     xlab = 'Validator selected'
     )
```

## PROCESS OF SELECTING SYNC COMMITTEE MEMBERS

 1. Shuffle index of validators (shuffled_index)
 2. Assign candidate index (candidate_index <- shuffled_index)
 3. Generate a random byte for that candidate
 4. Check if the candidate passes the test
 5. Yes - a. add to sync committee  if membership count is not yet 512
        - b. increment membership counter
 6. No - do not increment membership counter & pass through the loop again

```{r}
# We need to combine a candidate with the randomly generated value & check if it passes the test
# Note that a validator may be selected more than once & each time a new random byte will be assigned

#' EXAMPLE SCENARIO, PRE-EIP7521: 
#' ------------------------------
#' Total validator set size - 7,680, three stakers, each with 2,560 validators
# Shuffle the entire set each time to draw the next candidate
# -------------------------------------------------------------------------------------
active_validators_df <- tibble(
  staker = sample(c(rep("A",2560), rep("B",2560), rep("C", 2560))),
)

# Note we are assuming that all validators have 32 ETH EB
# Pre-EIP-7521 all validators will pass the sync committee check
# We are therefore only really looking at how many validators have been selected 
# more than once to join the sync committee

sync_committee_df <- assign_sync_committee(active_validators_df)
sync_committee_unique_df <- assign_unique_sync_mbrs(sync_committee_df) 

# Running the above grouping had values of 490 and 495 unique validators.
# Being a small validator set this is unsurprising

# Check staker representation in the sync committee
# Appears to be a similar distribution for the 3 staking groups in the large active validator set
sync_staker_totals_df <- assign_total_sync_stakers(sync_committee_df)

# Perhaps we need to do this for the current validator set size!!
# Using 900,000 for active validator set size & repeat the above procedure
# ========================================================================
active_validators_df_now <- tibble(
  staker = sample(c(rep("A",300000), rep("B",300000), rep("C", 300000))),
  selected = rep(0,900000)
)
sync_committee_df_now <- assign_sync_committee(active_validators_df_now)
sync_committee_unique_df_now <- assign_unique_sync_mbrs(sync_committee_df_now) 

# As expected no duplicates when the active validator set is so large, there were no validators
# elected to the sync committee more than once ^^

# Let us also look at how the stakers fared. They all had the same number of validators and 
# all validators had 32 ETH with MaxEB = 32 ETH
sync_staker_totals_df_now <- assign_total_sync_stakers(sync_committee_df_now)

## TODO: Plot proportion of stake (each 1/3) against the proportional 
## ----  representation in the sync committee (A: 152/512, B: 187/512, C: 173/512)
##                                            (A: 0.298,   B: 0.365,   C: 0.338 )
# ======================================================================================
```


```{r}
# Sync committee selection post-EIP-7521
# --------------------------------------
active_validators_df_maxeb <- tibble(
  staker = c(rep("A",2560), rep("B",40), rep("C", 520)),
  EB = c(rep(32,2560), rep(2048,40), rep(32,280), rep(64,100), rep(320,40), rep(2048,20))
)

## CONTINUE HERE TOMORROW!!!!

# Post-EIP-7521 for three staking groups: A, B & C
scenario_post_EIP7521_prob_A <- 2560/3020   # single stake (unconsolidated)
scenario_post_EIP7521_prob_B <- 40/3020     # maxEB stake
scenario_post_EIP7521_prob_C <- 520/3020    # varying consolidation 

# Post-EIP-7521 for four consolidated validator types
scenario_post_EIP7521_prob_single  <- 2840/3020  #  1 x 32 ETH
scenario_post_EIP7521_prob_single  <- 100/3020    #  2 x 32 ETH
scenario_post_EIP7521_prob_5_fold  <- 80/3020    #  5 x 32 ETH
scenario_post_EIP7521_prob_10_fold <- 40/3020    # 10 x 32 ETH
scenario_post_EIP7521_prob_maxEB   <- 60/3020    # 64 x 32 ETH



```


```{r}
validator_idx <- seq(0,716799)
proposers_scenario_1_DF <- tibble(validator_idx, r_int)

# Proposed situation: MaxEB = 2048 ETH
proposers_scenario_1_DF_MaxEB <- proposers_scenario_1_DF %>%
  mutate(selected = case_when(
      r_int <= (255*32)/2048 ~ "yes",
      TRUE ~ "no")
    )
maxeb_solo <- proposers_scenario_1_DF_MaxEB %>% 
  count(selected)

# Current situation: MaxEB = 32 ETH
proposers_scenario_1_DF_current <- proposers_scenario_1_DF %>%
  mutate(selected = case_when(
      r_int <= (255*32)/32 ~ "yes",
      TRUE ~ "no")
    )

# As expected all single stake validators pass the proposer check
current_solo <- proposers_scenario_1_DF_current %>% 
  count(selected)

solo_probability_maxeb <- maxeb_solo$n[2]/716800        # 0.01556, so a bit different to the 0.01395 probability calculated previously when iterating over all the 
                                                        # possible outcomes, but not far off the mark - 0.00161. However this is the outcome for seed(1). 
                                                        # 

# Check to see which validator indices were set to "accept"
# ----------------------------------------------------------
selected_validators <- proposers_scenario_1_DF_MaxEB %>%
  filter(selected == "yes")

first_selected_validator <- selected_validators$validator_idx[1]           ## >>> This was 26, so not a big deal really!!

```

## Scenario 2: All the validators have consolidated to the new increased maximum effective balance

-   Using total deposit size as before, i.e. equivalent to 716,800
    validators, will now have an active validator set size of 11,200
-   Generate random bytes to simulate a possible outcome of random bytes
    assigned to each validator.
-   The probability of being chosen based on the effective balance will
    again be 100%, so really this scenario is not of interest, just
    interesting to see how small it got.

## Scenario 3: The active validator set comprises of a "mixed bag" of validators: single stakers, partially consolidated and fully consolidated
This scenario is what is captured in the OOBN.

Based on the 716,800 active validator set:
- five categories of stakers
- six variations on the extent of consolidation of stake:

-   32 ETH     (A) - 1x
-   64 ETH     (B) - 2x
-  160 ETH     (C) - 5x
-  320 ETH     (D) - 10x
-  960 ETH     (E) - 20x
- 2048 ETH     (F) - 64x

The active validator set size is adjusted based on the consolidation of stake   

First shuffle the validator types & then generate random bytes for each validator before running through the check for acceptance.


```{r}
set.seed(5394)       # set some other random seed

initial_validator_set_total <- 716800

# Validator stake consolidation
validator_consolidation_DF <- tibble(
  name = c("32ETH", "64ETH", "160ETH", "320ETH", "960ETH", "2048ETH"),
  code = c("A","B","C","D","E","F")
)

# Distribution of staker categories in the active validator set
stakers_DF <- tibble(
  name = c("small", "large individual", "large institutional", "centralised", "semi-decentralised"),
  code = c("S1","S2", "S3", "S4", "S5"),
  proportion = c(0.3,0.15,0.15,0.1,0.3),
  
  # Consolidation of stake for each staker category:
  consolidation = list(
    tibble(A=0.4,B=0.4,C=0.2,D=0,E=0,F=0),              # small staker
    tibble(A=0.2,B=0.2,C=0.2,D=0.2,E=0.1,F=0.1),        # large indiv
    tibble(A=0.15,B=0.15,C=0.1,D=0.1,E=0.2,F=0.3),      # large institutional
    tibble(A=0.25,B=0.25,C=0.15,D=0.15,E=0.1,F=0.1),    # centralised
    tibble(A=0.3,B=0.2,C=0.1,D=0.1,E=0.1,F=0.2)         # semi-decentralised 
  )
)

# Staker category totals based on an example distribution of number of validators being run by each staking category
# ------------------------------------------------------------------------------------------------------------------
stakers_DF <- stakers_DF %>%
  mutate(totals = proportion*active_validator_set_total)

# Check validator set total
sum(stakers_DF$totals)


# Unnest the consolidation proportions
stakers_DF_flat <- stakers_DF %>%
  unnest(consolidation)

# Working as I was hoping it would, i.e. multiplying totals[1] across 1st elements of A,B, ...
# Now need to incorporate the actual consolidation too - reducing the actual numbers of the various types of validators
# Possibly need to take floor function as an approximation?
# ---------------------------------------------------------------------------------------------------------------------
# Rounding down totals so we only have "fully consolidated - by type" validators
stakers_DF_flat <- stakers_DF_flat %>%
  mutate(Atot = A*totals) %>%              #    32 ETH
  mutate(Btot = floor(B*totals/2))  %>%    #    64 ETH
  mutate(Ctot = floor(C*totals/5))  %>%    #   160 ETH
  mutate(Dtot = floor(D*totals/10)) %>%    #   320 ETH
  mutate(Etot = floor(E*totals/30)) %>%    #   960 ETH
  mutate(Ftot = floor(F*totals/64))        # 2,048 ETH

# No rounding - so "fractional" validators possible - which is the way things are handled in the BN model
stakers_DF_flat_not_rounded_down <- stakers_DF_flat %>%
  mutate(Atot = A*totals) %>%       #    32 ETH
  mutate(Btot = B*totals/2)  %>%    #    64 ETH
  mutate(Ctot = C*totals/5)  %>%    #   160 ETH
  mutate(Dtot = D*totals/10) %>%    #   320 ETH
  mutate(Etot = E*totals/30) %>%    #   960 ETH
  mutate(Ftot = F*totals/64)        # 2,048 ETH

# Round to the nearest full validator (in the real world this won't happen & stake not able to be consolidated to the extent desired will likely
# be assigned to smaller validators (i.e. less consolidated)
stakers_DF_flat_rounded <- stakers_DF_flat %>%
  mutate(Atot = A*totals) %>%              #    32 ETH
  mutate(Btot = round(B*totals/2,0))  %>%    #    64 ETH
  mutate(Ctot = round(C*totals/5,0))  %>%    #   160 ETH
  mutate(Dtot = round(D*totals/10,0))  %>%   #   320 ETH
  mutate(Etot = round(E*totals/30,0)) %>%    #   960 ETH
  mutate(Ftot = round(F*totals/64,0))        # 2,048 ETH

# Look at marking the validators with the staking category they belong to
validator_consolidation_DF <- validator_consolidation_DF %>%
  mutate(total = c(sum(stakers_DF_flat$Atot),
                  sum(stakers_DF_flat$Btot),
                  sum(stakers_DF_flat$Ctot),
                  sum(stakers_DF_flat$Dtot),
                  sum(stakers_DF_flat$Etot),
                  sum(stakers_DF_flat$Ftot)))

# No rounding - so "fractional" validators possible ;-)
validator_consolidation_DF_not_rounded_down <- validator_consolidation_DF %>%
  mutate(total = c(sum(stakers_DF_flat_not_rounded_down$Atot),
                  sum(stakers_DF_flat_not_rounded_down$Btot),
                  sum(stakers_DF_flat_not_rounded_down$Ctot),
                  sum(stakers_DF_flat_not_rounded_down$Dtot),
                  sum(stakers_DF_flat_not_rounded_down$Etot),
                  sum(stakers_DF_flat_not_rounded_down$Ftot)))

validator_consolidation_DF_rounded <- validator_consolidation_DF %>%
  mutate(total = c(sum(stakers_DF_flat_rounded$Atot),
                  sum(stakers_DF_flat_rounded$Btot),
                  sum(stakers_DF_flat_rounded$Ctot),
                  sum(stakers_DF_flat_rounded$Dtot),
                  sum(stakers_DF_flat_rounded$Etot),
                  sum(stakers_DF_flat_rounded$Ftot)))

# What is the new total for the validator set after consolidation?
# Using the floor function - came to 329,803. With BN model the total was 329,810.13
# ----------------------------------------------------------------------------------
adj_validator_total <- sum(validator_consolidation_DF$total)
adj_validator_total_not_rounded_down <- sum(validator_consolidation_DF_not_rounded_down$total)
adj_validator_total_rounded <- sum(validator_consolidation_DF_rounded$total)

# TODO:
# -----
# - Of the ones from the various consolidation types that pass the test, what were the proportions for each type of validator?
# - What do the proportion of validator types in the active validator set compare to the proportions that passed the proposer check?


# Construct a tibble for each validator type
# ------------------------------------------
# Floor values
validator_A <- tibble(
  staker = c(rep("S1",stakers_DF_flat$Atot[1]),
             rep("S2",stakers_DF_flat$Atot[2]),
             rep("S3",stakers_DF_flat$Atot[3]),
             rep("S4",stakers_DF_flat$Atot[4]),
             rep("S5",stakers_DF_flat$Atot[5])),
  type = rep("A",sum(stakers_DF_flat$Atot))
  )
# Rounded values
validator_A_rounded <- tibble(
  staker = c(rep("S1",stakers_DF_flat_rounded$Atot[1]),
             rep("S2",stakers_DF_flat_rounded$Atot[2]),
             rep("S3",stakers_DF_flat_rounded$Atot[3]),
             rep("S4",stakers_DF_flat_rounded$Atot[4]),
             rep("S5",stakers_DF_flat_rounded$Atot[5])),
  type = rep("A",sum(stakers_DF_flat_rounded$Atot))
  )

# Floor values
validator_B <- tibble(
  staker = c(rep("S1",stakers_DF_flat$Btot[1]),
             rep("S2",stakers_DF_flat$Btot[2]),
             rep("S3",stakers_DF_flat$Btot[3]),
             rep("S4",stakers_DF_flat$Btot[4]),
             rep("S5",stakers_DF_flat$Btot[5])),
  type = rep("B",sum(stakers_DF_flat$Btot))
  )
# Rounded values
validator_B_rounded <- tibble(
  staker = c(rep("S1",stakers_DF_flat_rounded$Btot[1]),
             rep("S2",stakers_DF_flat_rounded$Btot[2]),
             rep("S3",stakers_DF_flat_rounded$Btot[3]),
             rep("S4",stakers_DF_flat_rounded$Btot[4]),
             rep("S5",stakers_DF_flat_rounded$Btot[5])),
  type = rep("B",sum(stakers_DF_flat_rounded$Btot))
  )

# Floor values
validator_C <- tibble(
  staker = c(rep("S1",stakers_DF_flat$Ctot[1]),
             rep("S2",stakers_DF_flat$Ctot[2]),
             rep("S3",stakers_DF_flat$Ctot[3]),
             rep("S4",stakers_DF_flat$Ctot[4]),
             rep("S5",stakers_DF_flat$Ctot[5])),
  type = rep("C",sum(stakers_DF_flat$Ctot))
  )
# Rounded values
validator_C_rounded <- tibble(
  staker = c(rep("S1",stakers_DF_flat_rounded$Ctot[1]),
             rep("S2",stakers_DF_flat_rounded$Ctot[2]),
             rep("S3",stakers_DF_flat_rounded$Ctot[3]),
             rep("S4",stakers_DF_flat_rounded$Ctot[4]),
             rep("S5",stakers_DF_flat_rounded$Ctot[5])),
  type = rep("C",sum(stakers_DF_flat_rounded$Ctot))
  )

# Floor values
validator_D <- tibble(
  staker = c(rep("S1",stakers_DF_flat$Dtot[1]),
             rep("S2",stakers_DF_flat$Dtot[2]),
             rep("S3",stakers_DF_flat$Dtot[3]),
             rep("S4",stakers_DF_flat$Dtot[4]),
             rep("S5",stakers_DF_flat$Dtot[5])),
  type = rep("D",sum(stakers_DF_flat$Dtot))
  )
# Rounded values
validator_D_rounded <- tibble(
  staker = c(rep("S1",stakers_DF_flat_rounded$Dtot[1]),
             rep("S2",stakers_DF_flat_rounded$Dtot[2]),
             rep("S3",stakers_DF_flat_rounded$Dtot[3]),
             rep("S4",stakers_DF_flat_rounded$Dtot[4]),
             rep("S5",stakers_DF_flat_rounded$Dtot[5])),
  type = rep("D",sum(stakers_DF_flat_rounded$Dtot))
  )

# Floor values
validator_E <- tibble(
  staker = c(rep("S1",stakers_DF_flat$Etot[1]),
             rep("S2",stakers_DF_flat$Etot[2]),
             rep("S3",stakers_DF_flat$Etot[3]),
             rep("S4",stakers_DF_flat$Etot[4]),
             rep("S5",stakers_DF_flat$Etot[5])),
  type = rep("E",sum(stakers_DF_flat$Etot))
  )    
# Rounded values
validator_E_rounded <- tibble(
  staker = c(rep("S1",stakers_DF_flat_rounded$Etot[1]),
             rep("S2",stakers_DF_flat_rounded$Etot[2]),
             rep("S3",stakers_DF_flat_rounded$Etot[3]),
             rep("S4",stakers_DF_flat_rounded$Etot[4]),
             rep("S5",stakers_DF_flat_rounded$Etot[5])),
  type = rep("E",sum(stakers_DF_flat_rounded$Etot))
  )

# Floor values               
validator_F <- tibble(
  staker = c(rep("S1",stakers_DF_flat$Ftot[1]),
             rep("S2",stakers_DF_flat$Ftot[2]),
             rep("S3",stakers_DF_flat$Ftot[3]),
             rep("S4",stakers_DF_flat$Ftot[4]),
             rep("S5",stakers_DF_flat$Ftot[5])),
  type = rep("F",sum(stakers_DF_flat$Ftot))
  )   
# Rounded values
validator_F_rounded <- tibble(
  staker = c(rep("S1",stakers_DF_flat_rounded$Ftot[1]),
             rep("S2",stakers_DF_flat_rounded$Ftot[2]),
             rep("S3",stakers_DF_flat_rounded$Ftot[3]),
             rep("S4",stakers_DF_flat_rounded$Ftot[4]),
             rep("S5",stakers_DF_flat_rounded$Ftot[5])),
  type = rep("F",sum(stakers_DF_flat_rounded$Ftot))
  )  


# Combine all the various validator types along with the staker group they belong to & then we can add random bytes to the validators,
# shuffle the validators and see who passes the proposer eligibility test
# -----------------------------------------------------------------------------------------------------------------------------------
adjusted_validator_set_DF <- validator_A %>%
  add_row(validator_B) %>%
  add_row(validator_C) %>%
  add_row(validator_D) %>%
  add_row(validator_E) %>%
  add_row(validator_F)

# Rounded values
adjusted_validator_set_DF_rounded <- validator_A_rounded %>%
  add_row(validator_B_rounded) %>%
  add_row(validator_C_rounded) %>%
  add_row(validator_D_rounded) %>%
  add_row(validator_E_rounded) %>%
  add_row(validator_F_rounded)
  
# Generate random bytes for the adjusted validator set
random_byte_values_scenario3 <- runif(adj_validator_total,0,255)                   # floor
random_byte_values_scenario3_rounded <- runif(adj_validator_total_rounded,0,255)   # rounded

r_int_scenario3 <- floor(random_byte_values_scenario3)                             # floor
r_int_scenario3_rounded <- floor(random_byte_values_scenario3_rounded)             # rounded

# Floor values
# -------------
adjusted_validator_set_DF_scenario_3 <- adjusted_validator_set_DF %>%
  mutate(validator_idx = sample(seq(0,adj_validator_total-1))) %>%              # shuffle the validators      
  mutate(r_int = r_int_scenario3) %>%                                            # assign random bytes
  mutate(selected = case_when(                                                   # see which validators passed the proposer eligibility check
      (type == "A") & (r_int <= (255*32)/2048) ~ "yes",
      (type == "B") & (r_int <= (255*64)/2048) ~ "yes",
      (type == "C") & (r_int <= (255*160)/2048) ~ "yes",
      (type == "D") & (r_int <= (255*320)/2048) ~ "yes",
      (type == "E") & (r_int <= (255*960)/2048) ~ "yes",
      (type == "F") & (r_int <= (255*2048)/2048) ~ "yes",
      TRUE ~ "no"))

# Rounded values
adjusted_validator_set_DF_scenario_3_rounded <- adjusted_validator_set_DF_rounded %>%
  mutate(validator_idx = sample(seq(0,adj_validator_total_rounded-1))) %>%              # shuffle the validators      
  mutate(r_int = r_int_scenario3_rounded) %>%                                            # assign random bytes
  mutate(selected = case_when(                                                   # see which validators passed the proposer eligibility check
      (type == "A") & (r_int <= (255*32)/2048) ~ "yes",
      (type == "B") & (r_int <= (255*64)/2048) ~ "yes",
      (type == "C") & (r_int <= (255*160)/2048) ~ "yes",
      (type == "D") & (r_int <= (255*320)/2048) ~ "yes",
      (type == "E") & (r_int <= (255*960)/2048) ~ "yes",
      (type == "F") & (r_int <= (255*2048)/2048) ~ "yes",
      TRUE ~ "no"))

# Floor values
selected_validators_scenario_3 <- adjusted_validator_set_DF_scenario_3 %>%
  filter(selected=="yes")

# Rounded values
selected_validators_scenario_3_rounded <- adjusted_validator_set_DF_scenario_3_rounded %>%
  filter(selected=="yes")

## CONTINUE HERE !!!
## - DISTINGUISH BETWEEN PROBABILITIES WITHIN GROUPS/TYPES/CATEGORIES AND OVERALL VALIDATOR SET!!

# Floor values
scenario_3_count_validator_type <- adjusted_validator_set_DF_scenario_3 %>% 
  group_by(type) %>%
  count(selected) %>%
  mutate(prob=case_when(
    (type == "A") ~ n/sum(stakers_DF_flat$Atot),
    (type == "B") ~ n/sum(stakers_DF_flat$Btot),
    (type == "C") ~ n/sum(stakers_DF_flat$Ctot),
    (type == "D") ~ n/sum(stakers_DF_flat$Dtot),
    (type == "E") ~ n/sum(stakers_DF_flat$Etot),
    (type == "F") ~ n/sum(stakers_DF_flat$Ftot),
      TRUE ~ 0
  )) 

# Rounded values
scenario_3_count_validator_type_rounded <- adjusted_validator_set_DF_scenario_3 %>% 
  group_by(type) %>%
  count(selected) %>%
  mutate(prob=case_when(
    (type == "A") ~ n/sum(stakers_DF_flat_rounded$Atot),
    (type == "B") ~ n/sum(stakers_DF_flat_rounded$Btot),
    (type == "C") ~ n/sum(stakers_DF_flat_rounded$Ctot),
    (type == "D") ~ n/sum(stakers_DF_flat_rounded$Dtot),
    (type == "E") ~ n/sum(stakers_DF_flat_rounded$Etot),
    (type == "F") ~ n/sum(stakers_DF_flat_rounded$Ftot),
      TRUE ~ 0
  ))

scenario_3_count_staker_category <- adjusted_validator_set_DF_scenario_3 %>% 
  group_by(staker) %>%
  count(selected) %>%
  mutate(prob=case_when(
    (staker == "S1") ~ n/stakers_DF_flat$totals[1],
    (staker == "S2") ~ n/stakers_DF_flat$totals[2],
    (staker == "S3") ~ n/stakers_DF_flat$totals[3],
    (staker == "S4") ~ n/stakers_DF_flat$totals[4],
    (staker == "S5") ~ n/stakers_DF_flat$totals[5],
      TRUE ~ 0
  ))

# Using floor values: 
# Prepare data for plotting
# ----------------------------
scenario3_barchart_data <- tibble(
  type = scenario_3_count_validator_type$type,
  selected = scenario_3_count_validator_type$selected,
  total = scenario_3_count_validator_type$n,
  prob = scenario_3_count_validator_type$prob
) %>%
add_row(type="F", selected = "no", total=0, prob = 0)                    # Add row for MaxEB validators who are all selected

# CONTINUE HERE ON MONDAY OR TUESDAY!! 
# LOOK AT HOW I CAN ADD A BOX MAPPING VALIDATOR TYPES TO ETH, OR CHANGING THE LABELS ON THE PLOT
# ===============================================================================================>>>>>

# Bar chart of the totals for each validator type that passed or failed the proposer check
scenario3_barchart <- ggplot(data=scenario3_barchart_data) + 
  #geom_col(aes(x=type,y=n,  fill=selected)) +                           # single stacked bar per validator type
  geom_col(aes(x=type,y=total,  fill=selected), position = "dodge") +
  geom_text(mapping = aes(x=type,y=total,label = case_when(selected == "no" ~ paste0("(", total, ")"),
                                                   TRUE ~ "")), 
            nudge_y = 2, nudge_x = -0.2, fontface = "italic") +
  xlab("Was candidate index selected as proposer?") +
  ylab("Number of validators") +
  labs(fill = "Passed proposer test?") 

ggsave("/Users/sandra/data/rig/plots/scenario3_barchart_totals.png")

# Bar chart of the proportions for each validator type that passed or failed the proposer check
scenario3_barchart_prob <- ggplot(data=scenario3_barchart_data) + 
  #geom_col(aes(x=type,y=prob,  fill=selected)) +                           # single stacked bar per validator type
  geom_col(aes(x=type,y=prob,  fill=selected), position = "dodge") +
  xlab("Was candidate index selected as proposer?") +
  ylab("Validator proportions") +

ggsave("/Users/sandra/data/rig/plots/scenario3_barchart_prop.png")
```
## Testing section 
Trying code from various sources

```{r}
# The code below comes from stat.ethz.ch 

require(graphics)
# Compute P(45 < X < 55) for X Binomial(100,0.5)
sum(dbinom(46:54, 100, 0.5))

## Using "log = TRUE" for an extended range :
n <- 2000
k <- seq(0, n, by = 20)
plot (k, dbinom(k, n, pi/10, log = TRUE), type = "l", ylab = "log density",
      main = "dbinom(*, log=TRUE) is better than  log(dbinom(*))")
lines(k, log(dbinom(k, n, pi/10)), col = "red", lwd = 2)
## extreme points are omitted since dbinom gives 0.
mtext("dbinom(k, log=TRUE)", adj = 0)
mtext("extended range", adj = 0, line = -1, font = 4)
mtext("log(dbinom(k))", col = "red", adj = 1)

# Trying something out
x <- seq(0:255)
size <- 255
prob <- 1/3

plot(dbinom(x, size, prob, log = FALSE))
pbinom(q, size, prob, lower.tail = TRUE, log.p = FALSE)

```

